{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d1bcf29ac2d30483"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:55:08.304994Z",
     "start_time": "2024-09-20T15:55:07.483375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# \n",
    "# df = pd.read_csv('books.csv')\n",
    "# df.head()\n",
    "# Removing duplicates\n",
    "# df.duplicated(subset='Title').sum()\n",
    "# df = df.drop_duplicates(subset='Title')\n",
    "# df.duplicated(subset='Title').sum()\n",
    "# Random sampling\n",
    "# sample_size = 200\n",
    "# df = df.sample(n=sample_size , replace=False , random_state=100)\n",
    "# df = df.reset_index()\n",
    "# df = df.drop('index' , axis=1)\n",
    "# df.head()\n",
    "# df.info()\n",
    "\n",
    "# Processing Text data \n",
    "# def clean_text(author):\n",
    "#     result = str(author).lower()\n",
    "#     return(result.replace(' ',''))\n",
    "# df['Author'] = df['Author'].apply(clean_text)\n",
    "# df['Title'] = df['Title'].str.lower()\n",
    "# df['Publisher'] = df['Publisher'].str.lower()\n",
    "# df2 = df.drop(['Height','Genre'],axis=1)\n",
    "# df2['data'] = df2[df2.columns[1:]].apply(\n",
    "#     lambda x: ' '.join(x.dropna().astype(str)),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# print(df2['data'].head())\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorized = vectorizer.fit_transform(df2['data'])\n",
    "# \n",
    "# similarities = cosine_similarity(vectorized)\n",
    "# df = pd.DataFrame(similarities, columns=df['Title'], index=df['Title']).reset_index()\n",
    "# df.head()\n",
    "# input_book = 'we the living'\n",
    "# if input_book in df['Title'].values:\n",
    "#     recommendations = pd.DataFrame(df.nlargest(11, input_book)['Title'])\n",
    "#     recommendations = recommendations[recommendations['Title'] != input_book]\n",
    "#     print(recommendations)\n",
    "# else:\n",
    "#     print(f\"'{input_book}' not found in the dataset.\")"
   ],
   "id": "699ce1ab09a66cad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     id              title   latitude  \\\n",
       "0  bfa7bc92-b468-4080-bb15-2e87b7598c60       MERN Stack 5  37.774900   \n",
       "1  cf5380a9-fdff-4788-905b-3b8f23c4149c       MERN Stack 5  37.774900   \n",
       "2  58f86a3f-6edf-455b-a04b-baca4b25753f  Reacjts Developer  57.149606   \n",
       "3  2be6aae2-7616-4c8f-9ce0-3a2fc7d0b516          new title  57.149590   \n",
       "4  66ec5ac2-e378-46c6-b21c-815918aa4a96              hsheh  51.487122   \n",
       "\n",
       "    longitude                    city      state   zipCode  \\\n",
       "0 -122.419400           San Francisco         CA     94103   \n",
       "1 -122.419400           San Francisco         CA     94103   \n",
       "2   -2.096916           Aberdeen City        NaN  AB10 1AB   \n",
       "3   -2.096923          Aberdeen North  S99999999  AB10 1AF   \n",
       "4    0.003284  Greenwich and Woolwich  E99999999  SE10 0AA   \n",
       "\n",
       "                             jobType_id                        jobLocation_id  \\\n",
       "0  a0390368-ae9c-4c26-862a-8c5ef03aaff3  2c471f60-2f48-458a-92b2-36622fa6dad7   \n",
       "1  a0390368-ae9c-4c26-862a-8c5ef03aaff3  2c471f60-2f48-458a-92b2-36622fa6dad7   \n",
       "2  a0390368-ae9c-4c26-862a-8c5ef03aaff3  2c471f60-2f48-458a-92b2-36622fa6dad7   \n",
       "3  a0390368-ae9c-4c26-862a-8c5ef03aaff3  2c471f60-2f48-458a-92b2-36622fa6dad7   \n",
       "4  9f7c9074-9827-43a8-b4fe-fad57ab82008  2c471f60-2f48-458a-92b2-36622fa6dad7   \n",
       "\n",
       "   salary_min  ...                                            summary  \\\n",
       "0        1000  ...  Looking for a skilled software engineer to joi...   \n",
       "1        1000  ...  Looking for a skilled software engineer to joi...   \n",
       "2       50000  ...                        Job Seeker Wiill Be Success   \n",
       "3       16000  ...                                         new summar   \n",
       "4       26000  ...  \\n\\nThe job of a Laravel developer is to devel...   \n",
       "\n",
       "                                     jobRequirements radius  radiusUnit  \\\n",
       "0    5+ years of experience in software development.   50.0       miles   \n",
       "1    5+ years of experience in software development.   50.0       miles   \n",
       "2                        Job Seeker Wiill Be Success    1.0  kilometers   \n",
       "3                                    new reuqirments   25.0       miles   \n",
       "4  \\n\\nPosition: Laravel Developer\\n\\nLocation: I...   29.0       miles   \n",
       "\n",
       "                                user_id  \\\n",
       "0  477db199-d161-4ff8-8028-6b28ac7db579   \n",
       "1  477db199-d161-4ff8-8028-6b28ac7db579   \n",
       "2  ec23d0dd-f0da-4d6a-8620-a5c0713e2232   \n",
       "3  ee4ebfda-1a55-424a-8fcf-222725ffadba   \n",
       "4  d7a01d14-e031-47a1-bb6a-c3b231a20b87   \n",
       "\n",
       "                                            skill_id deactivate_at deleted_at  \\\n",
       "0             {f4b66805-90fc-40d5-a44b-40d84b26a32b}           NaN        NaN   \n",
       "1             {f4b66805-90fc-40d5-a44b-40d84b26a32b}           NaN        NaN   \n",
       "2  {f4b66805-90fc-40d5-a44b-40d84b26a32b,8e6e7223...           NaN        NaN   \n",
       "3             {5ad45909-4370-48e4-835d-d1fd4016e7cd}           NaN        NaN   \n",
       "4  {39ff8eed-e3db-4855-858b-066b552ad70b,5ad45909...           NaN        NaN   \n",
       "\n",
       "                      created_at                     updated_at  \n",
       "0  2024-09-15 14:22:48.718 -0700  2024-09-15 14:22:48.718 -0700  \n",
       "1  2024-09-15 15:43:53.890 -0700  2024-09-15 15:43:53.890 -0700  \n",
       "2  2024-09-16 14:54:24.666 -0700  2024-09-16 14:54:24.666 -0700  \n",
       "3  2024-09-19 04:40:01.444 -0700  2024-09-19 04:40:01.444 -0700  \n",
       "4  2024-09-18 11:06:56.933 -0700  2024-09-18 11:06:56.933 -0700  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipCode</th>\n",
       "      <th>jobType_id</th>\n",
       "      <th>jobLocation_id</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>...</th>\n",
       "      <th>summary</th>\n",
       "      <th>jobRequirements</th>\n",
       "      <th>radius</th>\n",
       "      <th>radiusUnit</th>\n",
       "      <th>user_id</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>deactivate_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfa7bc92-b468-4080-bb15-2e87b7598c60</td>\n",
       "      <td>MERN Stack 5</td>\n",
       "      <td>37.774900</td>\n",
       "      <td>-122.419400</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>a0390368-ae9c-4c26-862a-8c5ef03aaff3</td>\n",
       "      <td>2c471f60-2f48-458a-92b2-36622fa6dad7</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>Looking for a skilled software engineer to joi...</td>\n",
       "      <td>5+ years of experience in software development.</td>\n",
       "      <td>50.0</td>\n",
       "      <td>miles</td>\n",
       "      <td>477db199-d161-4ff8-8028-6b28ac7db579</td>\n",
       "      <td>{f4b66805-90fc-40d5-a44b-40d84b26a32b}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-15 14:22:48.718 -0700</td>\n",
       "      <td>2024-09-15 14:22:48.718 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf5380a9-fdff-4788-905b-3b8f23c4149c</td>\n",
       "      <td>MERN Stack 5</td>\n",
       "      <td>37.774900</td>\n",
       "      <td>-122.419400</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>a0390368-ae9c-4c26-862a-8c5ef03aaff3</td>\n",
       "      <td>2c471f60-2f48-458a-92b2-36622fa6dad7</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>Looking for a skilled software engineer to joi...</td>\n",
       "      <td>5+ years of experience in software development.</td>\n",
       "      <td>50.0</td>\n",
       "      <td>miles</td>\n",
       "      <td>477db199-d161-4ff8-8028-6b28ac7db579</td>\n",
       "      <td>{f4b66805-90fc-40d5-a44b-40d84b26a32b}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-15 15:43:53.890 -0700</td>\n",
       "      <td>2024-09-15 15:43:53.890 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58f86a3f-6edf-455b-a04b-baca4b25753f</td>\n",
       "      <td>Reacjts Developer</td>\n",
       "      <td>57.149606</td>\n",
       "      <td>-2.096916</td>\n",
       "      <td>Aberdeen City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AB10 1AB</td>\n",
       "      <td>a0390368-ae9c-4c26-862a-8c5ef03aaff3</td>\n",
       "      <td>2c471f60-2f48-458a-92b2-36622fa6dad7</td>\n",
       "      <td>50000</td>\n",
       "      <td>...</td>\n",
       "      <td>Job Seeker Wiill Be Success</td>\n",
       "      <td>Job Seeker Wiill Be Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kilometers</td>\n",
       "      <td>ec23d0dd-f0da-4d6a-8620-a5c0713e2232</td>\n",
       "      <td>{f4b66805-90fc-40d5-a44b-40d84b26a32b,8e6e7223...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-16 14:54:24.666 -0700</td>\n",
       "      <td>2024-09-16 14:54:24.666 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2be6aae2-7616-4c8f-9ce0-3a2fc7d0b516</td>\n",
       "      <td>new title</td>\n",
       "      <td>57.149590</td>\n",
       "      <td>-2.096923</td>\n",
       "      <td>Aberdeen North</td>\n",
       "      <td>S99999999</td>\n",
       "      <td>AB10 1AF</td>\n",
       "      <td>a0390368-ae9c-4c26-862a-8c5ef03aaff3</td>\n",
       "      <td>2c471f60-2f48-458a-92b2-36622fa6dad7</td>\n",
       "      <td>16000</td>\n",
       "      <td>...</td>\n",
       "      <td>new summar</td>\n",
       "      <td>new reuqirments</td>\n",
       "      <td>25.0</td>\n",
       "      <td>miles</td>\n",
       "      <td>ee4ebfda-1a55-424a-8fcf-222725ffadba</td>\n",
       "      <td>{5ad45909-4370-48e4-835d-d1fd4016e7cd}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-19 04:40:01.444 -0700</td>\n",
       "      <td>2024-09-19 04:40:01.444 -0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66ec5ac2-e378-46c6-b21c-815918aa4a96</td>\n",
       "      <td>hsheh</td>\n",
       "      <td>51.487122</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>Greenwich and Woolwich</td>\n",
       "      <td>E99999999</td>\n",
       "      <td>SE10 0AA</td>\n",
       "      <td>9f7c9074-9827-43a8-b4fe-fad57ab82008</td>\n",
       "      <td>2c471f60-2f48-458a-92b2-36622fa6dad7</td>\n",
       "      <td>26000</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n\\nThe job of a Laravel developer is to devel...</td>\n",
       "      <td>\\n\\nPosition: Laravel Developer\\n\\nLocation: I...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>miles</td>\n",
       "      <td>d7a01d14-e031-47a1-bb6a-c3b231a20b87</td>\n",
       "      <td>{39ff8eed-e3db-4855-858b-066b552ad70b,5ad45909...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-18 11:06:56.933 -0700</td>\n",
       "      <td>2024-09-18 11:06:56.933 -0700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:29:25.271862Z",
     "start_time": "2024-09-20T16:29:25.210219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Load CSV files\n",
    "job_df = pd.read_csv('jobs.csv')  # Job data\n",
    "job_location_df = pd.read_csv('jobLocation.csv')  # Job location data\n",
    "job_type_df = pd.read_csv('jobType.csv')  # Job type data\n",
    "merged_df = pd.merge(job_df, job_location_df, left_on='jobLocation_id', right_on='id', suffixes=('_job', '_location'))\n",
    "# Merge the result with job type data\n",
    "merged_df = pd.merge(merged_df, job_type_df, left_on='jobType_id', right_on='id', suffixes=('_merged', '_type'))\n",
    "merged_df.duplicated(subset='title_job').sum()\n",
    "merged_df = merged_df.drop_duplicates(subset='title_job')\n",
    "merged_df.duplicated(subset='title_job').sum()\n",
    "# Random sampling\n",
    "sample_size = 4\n",
    "merged_df = merged_df.sample(n=sample_size , replace=False , random_state=4)\n",
    "merged_df = merged_df.reset_index()\n",
    "merged_df = merged_df.drop('index' , axis=1)\n",
    "\n",
    "\n",
    "# Processing Text data \n",
    "def clean_text(author):\n",
    "    result = str(author).lower()\n",
    "    return(result.replace(' ',''))\n",
    "merged_df['city'] = merged_df['city'].apply(clean_text)\n",
    "merged_df['title_job'] = merged_df['title_job'].str.lower()\n",
    "merged_df['title_location'] = merged_df['title_location'].str.lower()\n",
    "merged_df['title'] = merged_df['title'].str.lower()\n",
    "df2 = merged_df.drop(['id_job','latitude' , 'longitude' , 'latitude' , 'state' ,'zipCode' , 'jobType_id'\n",
    "               , 'jobLocation_id' , 'salary_min' , 'salary_max' , 'summary' ,'jobRequirements',\n",
    "               'radius' , 'radiusUnit' , 'user_id' , 'skill_id' , 'deactivate_at' , 'deleted_at' , \n",
    "               'created_at_job' , 'updated_at_job' , 'id_location' , 'status_merged' ,'created_at_location' , 'updated_at_location' , 'id' , 'status_type' , 'created_at' , 'updated_at'],axis=1)\n",
    "df2['data'] = df2[df2.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# print(df2['data'].head())\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized = vectorizer.fit_transform(df2['data'])\n",
    "\n",
    "similarities = cosine_similarity(vectorized)\n",
    "merged_df = pd.DataFrame(similarities, columns=merged_df['title_job'], index=merged_df['title_job']).reset_index()\n",
    "# merged_df.head()\n",
    "job_title = 'mern stack'\n",
    "if job_title in merged_df['title_job'].values:\n",
    "    recommendations = pd.DataFrame(merged_df.nlargest(11, job_title)['title_job'])\n",
    "    recommendations = recommendations[recommendations['title_job'] != job_title]\n",
    "    print(recommendations)\n",
    "else:\n",
    "    print(f\"'{job_title}' not found in the dataset.\")\n"
   ],
   "id": "dc2d770edeebc456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         title_job\n",
      "1  react developer\n",
      "3       full stack\n",
      "2  react developer\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:46:43.135109Z",
     "start_time": "2024-09-20T16:46:43.061530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load CSV files\n",
    "job_df = pd.read_csv('jobs.csv')  # Job data\n",
    "job_location_df = pd.read_csv('jobLocation.csv')  # Job location data\n",
    "job_type_df = pd.read_csv('jobType.csv')  # Job type data\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_df = pd.merge(job_df, job_location_df, left_on='jobLocation_id', right_on='id', suffixes=('_job', '_location'))\n",
    "merged_df = pd.merge(merged_df, job_type_df, left_on='jobType_id', right_on='id', suffixes=('_merged', '_type'))\n",
    "\n",
    "# Remove duplicates and sample data\n",
    "merged_df = merged_df.drop_duplicates(subset='title_job').sample(n=4, replace=False, random_state=4).reset_index(drop=True)\n",
    "\n",
    "# Process text data\n",
    "def clean_text(text):\n",
    "    return str(text).lower().replace(' ', '')\n",
    "\n",
    "merged_df['city'] = merged_df['city'].apply(clean_text)\n",
    "merged_df['title_job'] = merged_df['title_job'].str.lower()\n",
    "\n",
    "# Combine job title and location\n",
    "merged_df['combined_features'] = merged_df['title_job'] + ' ' + merged_df['city']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df2 = merged_df.drop(['id_job', 'latitude', 'longitude', 'state', 'zipCode', 'jobType_id', 'jobLocation_id',\n",
    "                      'salary_min', 'salary_max', 'summary', 'jobRequirements', 'radius', 'radiusUnit', \n",
    "                      'user_id', 'skill_id', 'deactivate_at', 'deleted_at', 'created_at_job', 'updated_at_job',\n",
    "                      'id_location', 'status_merged', 'created_at_location', 'updated_at_location', \n",
    "                      'id', 'status_type', 'created_at', 'updated_at'], axis=1)\n",
    "\n",
    "# Create a new column with all relevant features combined\n",
    "df2['data'] = df2[df2.columns[1:]].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "# Vectorize the data for cosine similarity\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized = vectorizer.fit_transform(df2['data'])\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = cosine_similarity(vectorized)\n",
    "\n",
    "# Create a similarity DataFrame\n",
    "similarity_df = pd.DataFrame(similarities, columns=df2['combined_features'], index=df2['combined_features']).reset_index()\n",
    "\n",
    "# Search for job based on title and location\n",
    "job_title = 'react developer'\n",
    "job_location = 'faisalabad'\n",
    "search_term = f\"{job_title} {job_location}\"\n",
    "\n",
    "# Check if the job with the combined title and location exists\n",
    "if search_term in df2['combined_features'].values:\n",
    "    # Get the top 11 similar jobs (including the search term)\n",
    "    recommendations = pd.DataFrame(similarity_df.nlargest(11, search_term)['combined_features'])\n",
    "    \n",
    "    # If you want to include the search term itself in the recommendations, comment the next line\n",
    "    # recommendations = recommendations[recommendations['combined_features'] != search_term]\n",
    "    \n",
    "    print(f\"Recommendations for '{job_title}' in '{job_location}':\")\n",
    "    print(recommendations)\n",
    "else:\n",
    "    print(f\"'{search_term}' not found in the dataset.\")\n"
   ],
   "id": "5800b04849fe21a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'react developer' in 'faisalabad':\n",
      "            combined_features\n",
      "1  react developer faisalabad\n",
      "3           full stack lahore\n",
      "0        mern stack islamabad\n",
      "2     react developer karachi\n"
     ]
    }
   ],
   "execution_count": 108
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
